{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import classifier\n",
    "import modelnet\n",
    "\n",
    "batch_size = 1\n",
    "downsample = 2    #For 5000 points use 2, for 1000 use 10, for 100 use 100\n",
    "network_dim = 512  #For 5000 points use 512, for 1000 use 256, for 100 use 256\n",
    "num_repeats = 10    #Number of times to repeat the experiment\n",
    "data_path = 'ModelNet40_cloud.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_fetcher = modelnet.ModelFetcher(data_path, batch_size, downsample, do_standardize=True, do_augmentation=True)\n",
    "\n",
    "def eval_model(model_name):\n",
    "    D = classifier.DTanh(network_dim, pool='max1').cuda()\n",
    "    D.load_state_dict(torch.load(model_name))\n",
    "    D.eval()\n",
    "    counts = 0\n",
    "    sum_acc = 0.0\n",
    "    batch_results = []\n",
    "    batch_labels = []\n",
    "    batch_data = []\n",
    "    for x, _, y in model_fetcher.test_data():\n",
    "        counts += len(y)\n",
    "        X = Variable(torch.cuda.FloatTensor(x))\n",
    "        Y = Variable(torch.cuda.LongTensor(y))\n",
    "        f_X = D(X)\n",
    "        batch_results.append(f_X.detach().cpu().numpy())\n",
    "        batch_labels.append(y)\n",
    "        batch_data.append(x)\n",
    "        sum_acc += (f_X.max(dim=1)[1] == Y).float().sum().data.cpu().item()\n",
    "        del X,Y,f_X\n",
    "    test_acc = sum_acc/counts\n",
    "    results = np.concatenate(batch_results, 0)\n",
    "    labels = np.concatenate(batch_labels, 0)\n",
    "    data = np.concatenate(batch_data, 0)\n",
    "    print('Final Test Accuracy: {0:0.3f}'.format(test_acc))\n",
    "    print(results.shape)\n",
    "    return results, labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTanh(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui1_max(\n",
      "      (Gamma): Linear(in_features=3, out_features=512, bias=True)\n",
      "    )\n",
      "    (1): Tanh()\n",
      "    (2): PermEqui1_max(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (3): Tanh()\n",
      "    (4): PermEqui1_max(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (ro): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=512, out_features=40, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a356160ac0946c4819855988153a425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test Iterations: ', max=2467), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Final Test Accuracy: 0.900\n",
      "(2466, 40)\n"
     ]
    }
   ],
   "source": [
    "model_results_list = []\n",
    "for i in range(1):\n",
    "    mr, labels, data = eval_model('model_' + str(i + 1) + '.pt')\n",
    "    model_results_list.append(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2466, 5000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "np.save('xdata.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2466, 40, 10) (2466,)\n"
     ]
    }
   ],
   "source": [
    "model_results = np.stack(model_results_list, -1)\n",
    "print(model_results.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('probabilities.npy', model_results)\n",
    "np.save('true_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
